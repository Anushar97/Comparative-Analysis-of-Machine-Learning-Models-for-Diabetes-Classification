{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJ-fjAHrhcJL"
   },
   "source": [
    "## **STEP 1: Loading and understanding the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vX7FLZdDggs_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset = pd.read_csv('diabetic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SEzHrQ5bg6Zy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (101766, 50)\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             5346 non-null    object\n",
      " 23  A1Cresult                 17018 non-null   object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Display basic information\n",
    "print(\"Dataset Shape:\", dataset.shape)\n",
    "print(\"Dataset Info:\")\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8SwEPmgwhA4t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Rows of the Dataset:\n",
      "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
      "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
      "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
      "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
      "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
      "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
      "\n",
      "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
      "0                  6                        25                    1   \n",
      "1                  1                         1                    7   \n",
      "2                  1                         1                    7   \n",
      "3                  1                         1                    7   \n",
      "4                  1                         1                    7   \n",
      "\n",
      "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
      "0                 1  ...          No      No                   No   \n",
      "1                 3  ...          No      Up                   No   \n",
      "2                 2  ...          No      No                   No   \n",
      "3                 2  ...          No      Up                   No   \n",
      "4                 1  ...          No  Steady                   No   \n",
      "\n",
      "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
      "0                   No                        No                       No   \n",
      "1                   No                        No                       No   \n",
      "2                   No                        No                       No   \n",
      "3                   No                        No                       No   \n",
      "4                   No                        No                       No   \n",
      "\n",
      "   metformin-pioglitazone  change diabetesMed readmitted  \n",
      "0                      No      No          No         NO  \n",
      "1                      No      Ch         Yes        >30  \n",
      "2                      No      No         Yes         NO  \n",
      "3                      No      Ch         Yes         NO  \n",
      "4                      No      Ch         Yes         NO  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "print(\"First 5 Rows of the Dataset:\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nozVduRAhDs3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for Numerical Features:\n",
      "       encounter_id   patient_nbr  admission_type_id  \\\n",
      "count  1.017660e+05  1.017660e+05      101766.000000   \n",
      "mean   1.652016e+08  5.433040e+07           2.024006   \n",
      "std    1.026403e+08  3.869636e+07           1.445403   \n",
      "min    1.252200e+04  1.350000e+02           1.000000   \n",
      "25%    8.496119e+07  2.341322e+07           1.000000   \n",
      "50%    1.523890e+08  4.550514e+07           1.000000   \n",
      "75%    2.302709e+08  8.754595e+07           3.000000   \n",
      "max    4.438672e+08  1.895026e+08           8.000000   \n",
      "\n",
      "       discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
      "count             101766.000000        101766.000000     101766.000000   \n",
      "mean                   3.715642             5.754437          4.395987   \n",
      "std                    5.280166             4.064081          2.985108   \n",
      "min                    1.000000             1.000000          1.000000   \n",
      "25%                    1.000000             1.000000          2.000000   \n",
      "50%                    1.000000             7.000000          4.000000   \n",
      "75%                    4.000000             7.000000          6.000000   \n",
      "max                   28.000000            25.000000         14.000000   \n",
      "\n",
      "       num_lab_procedures  num_procedures  num_medications  number_outpatient  \\\n",
      "count       101766.000000   101766.000000    101766.000000      101766.000000   \n",
      "mean            43.095641        1.339730        16.021844           0.369357   \n",
      "std             19.674362        1.705807         8.127566           1.267265   \n",
      "min              1.000000        0.000000         1.000000           0.000000   \n",
      "25%             31.000000        0.000000        10.000000           0.000000   \n",
      "50%             44.000000        1.000000        15.000000           0.000000   \n",
      "75%             57.000000        2.000000        20.000000           0.000000   \n",
      "max            132.000000        6.000000        81.000000          42.000000   \n",
      "\n",
      "       number_emergency  number_inpatient  number_diagnoses  \n",
      "count     101766.000000     101766.000000     101766.000000  \n",
      "mean           0.197836          0.635566          7.422607  \n",
      "std            0.930472          1.262863          1.933600  \n",
      "min            0.000000          0.000000          1.000000  \n",
      "25%            0.000000          0.000000          6.000000  \n",
      "50%            0.000000          0.000000          8.000000  \n",
      "75%            0.000000          1.000000          9.000000  \n",
      "max           76.000000         21.000000         16.000000  \n"
     ]
    }
   ],
   "source": [
    "# Summary statistics for numerical features\n",
    "print(\"Summary Statistics for Numerical Features:\")\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EK1xDg5AhGJz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values per Column:\n",
      "max_glu_serum    96420\n",
      "A1Cresult        84748\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = dataset.isnull().sum()\n",
    "print(\"Missing Values per Column:\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ykdRtLnhqYd"
   },
   "source": [
    "## **STEP 2: Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UHcIYPbT3OcN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4bnQOVq-iCos"
   },
   "outputs": [],
   "source": [
    "# Remove 'weight' column due to high percentage of missing values\n",
    "dataset_cleaned = dataset.drop(columns=['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "r3L6rTN8kUUz"
   },
   "outputs": [],
   "source": [
    "# Treat missing values for 'medical_specialty' and 'payer_code' as 'Unknown'\n",
    "dataset_cleaned['medical_specialty'] = dataset_cleaned['medical_specialty'].replace('?', 'Unknown')\n",
    "dataset_cleaned['payer_code'] = dataset_cleaned['payer_code'].replace('?', 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9YizWskhkW8d"
   },
   "outputs": [],
   "source": [
    "# Impute missing values in 'race' with the mode\n",
    "race_mode = dataset_cleaned['race'].replace('?', pd.NA).mode()[0]\n",
    "dataset_cleaned['race'] = dataset_cleaned['race'].replace('?', race_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ulgBik_ekb78"
   },
   "outputs": [],
   "source": [
    "# Impute missing values in 'diag_1', 'diag_2', 'diag_3' with 'Unknown'\n",
    "diagnosis_cols = ['diag_1', 'diag_2', 'diag_3']\n",
    "for col in diagnosis_cols:\n",
    "    dataset_cleaned[col] = dataset_cleaned[col].replace('?', 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VjKWDCCIke-p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of 'readmitted':\n",
      " readmitted\n",
      "NO     53.911916\n",
      ">30    34.928169\n",
      "<30    11.159916\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Handling Class Imbalance (for informational purposes, actual handling might vary based on modeling approach)\n",
    "target_distribution = dataset_cleaned['readmitted'].value_counts(normalize=True) * 100\n",
    "print(\"Distribution of 'readmitted':\\n\", target_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6Irt8RrpkjA-"
   },
   "outputs": [],
   "source": [
    "# Feature Selection and Encoding\n",
    "\n",
    "# Selecting categorical variables for one-hot encoding\n",
    "categorical_cols = ['race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "                    'diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult'] + list(dataset_cleaned.columns[24:48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dz_Jd8GtkppH"
   },
   "outputs": [],
   "source": [
    "# Keeping relevant numerical columns and excluding identifiers\n",
    "numerical_cols = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications',\n",
    "                  'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8H3rpNL82i9q"
   },
   "outputs": [],
   "source": [
    "# Encoding categorical variables with OneHotEncoder and outputting as a sparse matrix to save memory\n",
    "encoder = OneHotEncoder(sparse_output=True, drop='first')  # Using sparse output to save memory\n",
    "encoded_features_sparse = encoder.fit_transform(dataset_cleaned[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "h5toDsptkwod"
   },
   "outputs": [],
   "source": [
    "# Since we're using sparse matrices, direct conversion to a DataFrame is skipped to save memory\n",
    "# Prepare numerical data as a DataFrame for potential dense input requirements\n",
    "numerical_data_df = dataset_cleaned[numerical_cols].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DH0MR6qXk0Gc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoded features: (101766, 2369)\n",
      "Shape of numerical data: (101766, 8)\n"
     ]
    }
   ],
   "source": [
    "# Output shapes as a check\n",
    "print(\"Shape of encoded features:\", encoded_features_sparse.shape)\n",
    "print(\"Shape of numerical data:\", numerical_data_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oOqN5Y5k_ui"
   },
   "source": [
    "## **STEP 3: Model Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NE9397QIECqp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Prepare the full feature set by combining numerical and encoded categorical features\n",
    "X = hstack([numerical_data_df, encoded_features_sparse])\n",
    "y = dataset_cleaned['readmitted'].apply(lambda x: 1 if x == '<30' else 0)  # Binary classification for readmission <30 days\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-SfdhiYqD0g"
   },
   "source": [
    "# **A. Single Machine Learning Algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cih74SiIpCen"
   },
   "source": [
    "**1. LOGISTIC REGRESSION MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "cFDx_piZJ9l6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8889967081019997\n",
      "Testing Accuracy: 0.888375749238479\n",
      "Training F1 Score: 0.049237243556023144\n",
      "Testing F1 Score: 0.04215851602023609\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=100, solver='liblinear', random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = lr_model.predict(X_train)\n",
    "y_pred_test = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_train = f1_score(y_train, y_pred_train)\n",
    "f1_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_train)\n",
    "print(\"Testing Accuracy:\", accuracy_test)\n",
    "print(\"Training F1 Score:\", f1_train)\n",
    "print(\"Testing F1 Score:\", f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdINvCebpbTK"
   },
   "source": [
    "**2. DECISION TREE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vWuQscADKQT5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Training Accuracy: 1.0\n",
      "Decision Tree - Testing Accuracy: 0.8226392846614916\n",
      "Decision Tree - Training F1 Score: 1.0\n",
      "Decision Tree - Testing F1 Score: 0.16551086453999075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_dt = dt_model.predict(X_train)\n",
    "y_pred_test_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_train_dt = accuracy_score(y_train, y_pred_train_dt)\n",
    "accuracy_test_dt = accuracy_score(y_test, y_pred_test_dt)\n",
    "f1_train_dt = f1_score(y_train, y_pred_train_dt)\n",
    "f1_test_dt = f1_score(y_test, y_pred_test_dt)\n",
    "\n",
    "print(\"Decision Tree - Training Accuracy:\", accuracy_train_dt)\n",
    "print(\"Decision Tree - Testing Accuracy:\", accuracy_test_dt)\n",
    "print(\"Decision Tree - Training F1 Score:\", f1_train_dt)\n",
    "print(\"Decision Tree - Testing F1 Score:\", f1_test_dt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQ2dFMAClSMX"
   },
   "source": [
    "**K-NEAREST NEIGHBORS (KNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "maZ1H6p1FjR0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NEAREST NEIGHBORS - Training Accuracy: 1.0\n",
      "K-NEAREST NEIGHBORS - Testing Accuracy: 0.8226392846614916\n",
      "K-NEAREST NEIGHBORS - Training F1 Score: 1.0\n",
      "K-NEAREST NEIGHBORS - Testing F1 Score: 0.16551086453999075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_knn = knn_model.predict(X_train)\n",
    "y_pred_test_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_train_knn = accuracy_score(y_train, y_pred_train_knn)\n",
    "accuracy_test_knn = accuracy_score(y_test, y_pred_test_knn)\n",
    "f1_train_knn = f1_score(y_train, y_pred_train_knn)\n",
    "f1_test_knn = f1_score(y_test, y_pred_test_knn)\n",
    "\n",
    "print(\"K-NEAREST NEIGHBORS - Training Accuracy:\", accuracy_train_dt)\n",
    "print(\"K-NEAREST NEIGHBORS - Testing Accuracy:\", accuracy_test_dt)\n",
    "print(\"K-NEAREST NEIGHBORS - Training F1 Score:\", f1_train_dt)\n",
    "print(\"K-NEAREST NEIGHBORS - Testing F1 Score:\", f1_test_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoUmvesVp_BR"
   },
   "source": [
    "**SUPPORT VECTOR MACHINE (SVM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rrFWyHxLFfwl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Training Accuracy: 1.0\n",
      "SVM - Testing Accuracy: 0.8226392846614916\n",
      "SVM - Training F1 Score: 1.0\n",
      "SVM - Testing F1 Score: 0.16551086453999075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = LinearSVC(random_state=42, max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_svm = svm_model.predict(X_train)\n",
    "y_pred_test_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_train_svm = accuracy_score(y_train, y_pred_train_svm)\n",
    "accuracy_test_svm = accuracy_score(y_test, y_pred_test_svm)\n",
    "f1_train_svm = f1_score(y_train, y_pred_train_svm)\n",
    "f1_test_svm = f1_score(y_test, y_pred_test_svm)\n",
    "\n",
    "print(\"SVM - Training Accuracy:\", accuracy_train_dt)\n",
    "print(\"SVM - Testing Accuracy:\", accuracy_test_dt)\n",
    "print(\"SVM - Training F1 Score:\", f1_train_dt)\n",
    "print(\"SVM - Testing F1 Score:\", f1_test_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LArw7H5ylYd-"
   },
   "source": [
    "**NAIVE BAYES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6JeNTSH8FmA6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAIVE BAYES - Training Accuracy: 1.0\n",
      "NAIVE BAYES - Testing Accuracy: 0.8226392846614916\n",
      "NAIVE BAYES - Training F1 Score: 1.0\n",
      "NAIVE BAYES - Testing F1 Score: 0.16551086453999075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Since Naive Bayes doesn't handle sparse data natively, convert to dense\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "# Train the model\n",
    "nb_model.fit(X_train_dense, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_nb = nb_model.predict(X_train_dense)\n",
    "y_pred_test_nb = nb_model.predict(X_test_dense)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_train_nb = accuracy_score(y_train, y_pred_train_nb)\n",
    "accuracy_test_nb = accuracy_score(y_test, y_pred_test_nb)\n",
    "f1_train_nb = f1_score(y_train, y_pred_train_nb)\n",
    "f1_test_nb = f1_score(y_test, y_pred_test_nb)\n",
    "\n",
    "print(\"NAIVE BAYES - Training Accuracy:\", accuracy_train_dt)\n",
    "print(\"NAIVE BAYES - Testing Accuracy:\", accuracy_test_dt)\n",
    "print(\"NAIVE BAYES - Training F1 Score:\", f1_train_dt)\n",
    "print(\"NAIVE BAYES - Testing F1 Score:\", f1_test_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDBquF3wld-9"
   },
   "source": [
    "## **B. Ensemble Learning Algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCt5B0Oall2v"
   },
   "source": [
    "**RANDOM FOREST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "fiVMfvVAEwqy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Training Accuracy: 0.9999877167985064\n",
      "Random Forest - Testing Accuracy: 0.8886214011987815\n",
      "Random Forest - Training F1 Score: 0.9999449672555171\n",
      "Random Forest - Testing F1 Score: 0.012200435729847494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_rf = rf_model.predict(X_train)\n",
    "y_pred_test_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_train_rf = accuracy_score(y_train, y_pred_train_rf)\n",
    "accuracy_test_rf = accuracy_score(y_test, y_pred_test_rf)\n",
    "f1_train_rf = f1_score(y_train, y_pred_train_rf)\n",
    "f1_test_rf = f1_score(y_test, y_pred_test_rf)\n",
    "\n",
    "print(\"Random Forest - Training Accuracy:\", accuracy_train_rf)\n",
    "print(\"Random Forest - Testing Accuracy:\", accuracy_test_rf)\n",
    "print(\"Random Forest - Training F1 Score:\", f1_train_rf)\n",
    "print(\"Random Forest - Testing F1 Score:\", f1_test_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a55BHG61lqlN"
   },
   "source": [
    "**GRADIENT BOOSTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vQHgUv75FoHz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT BOOSTING - Training Accuracy: 0.9999877167985064\n",
      "GRADIENT BOOSTING - Testing Accuracy: 0.8886214011987815\n",
      "GRADIENT BOOSTING - Training F1 Score: 0.9999449672555171\n",
      "GRADIENT BOOSTING - Testing F1 Score: 0.012200435729847494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_gb = gb_model.predict(X_train)\n",
    "y_pred_test_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_train_gb = accuracy_score(y_train, y_pred_train_gb)\n",
    "accuracy_test_gb = accuracy_score(y_test, y_pred_test_gb)\n",
    "f1_train_gb = f1_score(y_train, y_pred_train_gb)\n",
    "f1_test_gb = f1_score(y_test, y_pred_test_gb)\n",
    "\n",
    "print(\"GRADIENT BOOSTING - Training Accuracy:\", accuracy_train_rf)\n",
    "print(\"GRADIENT BOOSTING - Testing Accuracy:\", accuracy_test_rf)\n",
    "print(\"GRADIENT BOOSTING - Training F1 Score:\", f1_train_rf)\n",
    "print(\"GRADIENT BOOSTING - Testing F1 Score:\", f1_test_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGAZWy76luW-"
   },
   "source": [
    "**ADABOOST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8aJq1aFrFq3R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADABOOST - Training Accuracy: 0.9999877167985064\n",
      "ADABOOST - Testing Accuracy: 0.8886214011987815\n",
      "ADABOOST - Training F1 Score: 0.9999449672555171\n",
      "ADABOOST - Testing F1 Score: 0.012200435729847494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Initialize the AdaBoost model\n",
    "ab_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "ab_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_ab = ab_model.predict(X_train)\n",
    "y_pred_test_ab = ab_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_train_ab = accuracy_score(y_train, y_pred_train_ab)\n",
    "accuracy_test_ab = accuracy_score(y_test, y_pred_test_ab)\n",
    "f1_train_ab = f1_score(y_train, y_pred_train_ab)\n",
    "f1_test_ab = f1_score(y_test, y_pred_test_ab)\n",
    "\n",
    "print(\"ADABOOST - Training Accuracy:\", accuracy_train_rf)\n",
    "print(\"ADABOOST - Testing Accuracy:\", accuracy_test_rf)\n",
    "print(\"ADABOOST - Training F1 Score:\", f1_train_rf)\n",
    "print(\"ADABOOST - Testing F1 Score:\", f1_test_rf)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "7oOqN5Y5k_ui"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
